{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import nlp_dictionary as nlp_dictionary\n",
    "from nyt_topics_api import nyt_topics_sents\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nyt=nyt_topics_sents()\n",
    "nlp_my = nlp_dictionary.nlp_dictionary()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ela_quiz(sentence, word_to_blank, list_of_other_words):\n",
    "    ns = sentence.split()\n",
    "    for i in range (0, len(ns)):\n",
    "        if ns[i] == word_to_blank:\n",
    "            ns[i]=\"____\"\n",
    "    ens=\" \".join(ns)\n",
    "    print(ens)\n",
    "    array=random.sample(list_of_other_words, len(list_of_other_words))\n",
    "    alfalphbet=\"ABCDE\"\n",
    "    y = dict()\n",
    "    for x in range (0, len(array)):\n",
    "        print(alfalphbet[x], \".\" , array[x])\n",
    "        y[array[x]] = alfalphbet[x]\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'What he went on to achieve from those benignings was simply phenomanal .'\n",
    "word_to_blank = \"phenomanal\"\n",
    "list_of_other_words = [\"awesome\", \"intriguing\", \"phenomanal\", \"interesting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"Humans abilities to sense heat, cold, pressure and position are vital for perceiving and reacting to our \\\n",
    "surroundings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [str(t) for t in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Humans abilities to sense heat, cold, pressure and position are vital for perceiving and reacting to our surroundings.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandon', 'abide', 'abolish', 'abroad', 'absorb', 'absurd', 'abundant', 'abuse', 'accurate', 'acknowledge', 'addict', 'adequate', 'adolescent', 'alter', 'amateur', 'ambush', 'annual', 'anticipate', 'appeal', 'appoint', 'approach', 'appropriate', 'architect', 'assemble', 'attract', 'audible', 'authority', 'avoid', 'aware', 'awesome', 'awkward', 'bachelor', 'baffle', 'baggage', 'bait', 'ban', 'beckon', 'beneficiary', 'betray', 'bewildered', 'bigamy', 'biography', 'blunder', 'brawl', 'brutal', 'budget', 'bulky', 'burden', 'calamity', 'calculate', 'campus', 'cancel', 'candidate', 'capacity', 'capsule', 'captive', 'casual', 'caution', 'cease', 'censor', 'century', 'challenge', 'charity', 'chiropractor', 'cinema', 'circulate', 'clergy', 'client', 'coeducational', 'coincide', 'collapse', 'colleague', 'collide', 'commence', 'commend', 'commuter', 'compel', 'compete', 'complacent', 'comprehend', 'comprehensive', 'conceal', 'conclude', 'confident', 'confine', 'confirm', 'conflict', 'consider', 'contagious', 'corpse', 'crafty', 'culprit', 'customary', 'data', 'daze', 'debate', 'debtor', 'decade', 'deceive', 'decrease', 'defect', 'defiant', 'defraud', 'dejected', 'deliberate', 'delinquent', 'denounce', 'dense', 'depart', 'depict', 'deprive', 'descend', 'despite', 'detect', 'detest', 'detour', 'devise', 'devour', 'dilemma', 'diminish', 'disaster', 'discard', 'disclose', 'dismal', 'dispute', 'disrupt', 'distress', 'document', 'doubt', 'dread', 'drench', 'drought', 'duplicate', 'dwindle', 'economical', 'editor', 'elevate', 'eliminate', 'embrace', 'emerge', 'encourage', 'endure', 'enormous', 'envy', 'epidemic', 'essential', 'estimate', 'evade', 'event', 'evidence', 'exaggerate', 'excel', 'excessive', 'exempt', 'exhaust', 'exhibit', 'expand', 'expensive', 'explore', 'expose', 'extract', 'famine', 'feeble', 'feminine', 'fertile', 'fiction', 'fierce', 'final', 'finance', 'flee', 'flexible', 'forbid', 'fortunate', 'fragile', 'frank', 'frequent', 'frigid', 'fugitive', 'gallant', 'glance', 'gleam', 'glimpse', 'gloomy', 'grateful', 'guide', 'harmony', 'harsh', 'harvest', 'hasty', 'hazy', 'heed', 'heir', 'hesitate', 'hinder', 'homicide', 'horrid', 'humid', 'identify', 'idle', 'idol', 'ignite', 'ignore', 'illegal', 'illustrate', 'indifference', 'ingenious', 'inhabit', 'innovative', 'insist', 'jagged', 'jealous', 'jeopardize', 'jest', 'jolly', 'journalist', 'justice', 'juvenile', 'keen', 'keg', 'kneel', 'lack', 'lecture', 'legend', 'legible', 'linger', 'logical', 'lottery', 'loyalty', 'lubricate', 'lunatic', 'magnify', 'maim', 'maintain', 'majestic', 'majority', 'manipulate', 'masculine', 'matrimony', 'mature', 'maximum', 'mediocre', 'menace', 'merit', 'microscope', 'migrate', 'miniature', 'minimum', 'minority', 'miserly', 'misfortune', 'molest', 'monarch', 'morality', 'morgue', 'morsel', 'mortal', 'mount', 'mourn', 'multitude', 'mumble', 'municipal', 'mute', 'mythology', 'narcotic', 'negative', 'neglect', 'neutral', 'nimble', 'nominate', 'nourish', 'novel', 'numb', 'numerous', 'oath', 'obedient', 'obesity', 'observant', 'obstacle', 'obtain', 'obvious', 'occupant', 'opt', 'oral', 'outlaw', 'pacify', 'panic', 'parole', 'partial', 'patriotic', 'pauper', 'pedestrian', 'penalize', 'penetrate', 'pension', 'peril', 'perish', 'persist', 'persuade', 'pierce', 'pioneer', 'placard', 'plea', 'pledge', 'pollute', 'ponder', 'popular', 'population', 'possible', 'postpone', 'potential', 'precaution', 'precede', 'predict', 'prejudice', 'preoccupied', 'preserve', 'prior', 'probe', 'proceed', 'prohibit', 'prominent', 'promote', 'prompt', 'prosecute', 'prosper', 'provide', 'pursue', 'qualify', 'quantity', 'quarter', 'quench', 'quota', 'quote', 'radical', 'rage', 'rapid', 'rash', 'rave', 'recede', 'recent', 'reckless', 'recline', 'redeem', 'refer', 'reform', 'refrain', 'rehabilitate', 'reject', 'related', 'relieve', 'reluctant', 'repetition', 'reptile', 'resent', 'resign', 'resist', 'respond', 'resume', 'retain', 'reveal', 'revise', 'revive', 'rival', 'roam', 'rural', 'sacred', 'scald', 'scarce', 'scorch', 'scowl', 'security', 'sensitive', 'severity', 'shriek', 'shrill', 'signify', 'sinister', 'site', 'skim', 'slender', 'sneer', 'soar', 'solitary', 'soothe', 'source', 'spontaneous', 'spouse', 'squander', 'stationary', 'subsequent', 'subside', 'summit', 'surpass', 'surplus', 'survive', 'swarm', 'symbol', 'sympathetic', 'tact', 'talent', 'temperate', 'tempest', 'tempt', 'tendency', 'theory', 'thorough', 'threat', 'thrifty', 'thrust', 'toil', 'topic', 'torment', 'torrent', 'tradition', 'tragedy', 'traitor', 'transmit', 'transparent', 'trifle', 'tumult', 'typical', 'tyrant', 'unaccustomed', 'unanimous', 'undeniable', 'underdog', 'underestimate', 'undernourished', 'undoubtedly', 'unearth', 'uneasy', 'uneventful', 'unforeseen', 'unify', 'unite', 'unruly', 'unstable', 'untidy', 'upholstery', 'urban', 'urgent', 'utensil', 'utilize', 'utter', 'vacant', 'vaccinate', 'vague', 'vain', 'valiant', 'valid', 'valor', 'vandal', 'vanish', 'vapor', 'variety', 'vast', 'vein', 'ventilate', 'venture', 'verdict', 'verify', 'vermin', 'verse', 'vertical', 'vessel', 'vicinity', 'vicious', 'victorious', 'vigor', 'villain', 'violent', 'visible', 'vision', 'vital', 'vocation', 'volunteer', 'vulnerable', 'wad', 'wager', 'warden', 'wary', 'wasp', 'weary', 'weird', 'whirling', 'wholesale', 'witty', 'wobble', 'wrath', 'wretched', 'skim']\n"
     ]
    }
   ],
   "source": [
    "words = nlp_my.get_504_words()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_w_word (sents, words):\n",
    "    for v in range (len(sents)):\n",
    "        if words in sents[v].split():\n",
    "            return(sents[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "r=sent_w_word(sentences, words[3])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-84b3eb776b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_synonyms_spacy_english\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/derick/games/ela_games/nlp_dictionary.py\u001b[0m in \u001b[0;36mget_synonyms_spacy_english\u001b[0;34m(self, w, top)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_vector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebster_jdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_vector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_sim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/spacy/lexeme.pyx\u001b[0m in \u001b[0;36mspacy.lexeme.Lexeme.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.get_by_orth\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/spacy/lang/lex_attrs.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s = nlp_my.get_synonyms_spacy_english(words[3], 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'api_key',\n",
       " 'build_dict',\n",
       " 'get_all',\n",
       " 'get_topic',\n",
       " 'topics']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nyt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes = nyt.get_all(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selector in range (len(words)):\n",
    "    rs = sent_w_word(nytimes, words[selector])\n",
    "    if rs is not None:\n",
    "        word = words[selector]\n",
    "        list_of_other_words = [word] + s\n",
    "        ela_quiz(rs, word, list_of_other_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The crises in Benton Harbor and Flint ____ broader failures as a congressional push to address the countrys troubled water system stalls.\n",
      "A . hide\n",
      "B . engage\n",
      "C . expose\n",
      "D . manipulate\n",
      "C\n",
      "C\n",
      "correct\n",
      "Auto analysts ____ Rivian one of the most viable electric vehicle start-ups in what is expected to be a very competitive market.\n",
      "A . consider\n",
      "B . crucial\n",
      "C . employ\n",
      "D . frequently\n",
      "A\n",
      "A\n",
      "correct\n",
      "The Manheim Used Vehicle Value Index, an obscure tracker of ____ used-car prices, has become closely watched by the finance worlds high rollers.\n",
      "A . wholesale\n",
      "B . shop\n",
      "C . distributor\n",
      "D . price\n",
      "A\n",
      "A\n",
      "correct\n",
      "Some analysts say they cannot determine if plant-based foods are more sustainable than meat because the companies are not ____ about their emissions.\n",
      "A . transparent\n",
      "B . reflective\n",
      "C . thin\n",
      "D . flexible\n",
      "A\n",
      "A\n",
      "correct\n",
      "Maria Kowroski, the reigning principal of New York City Ballet and the last company member to have worked with Jerome Robbins, takes her ____ bow.\n",
      "A . final\n",
      "B . season\n",
      "C . winning\n",
      "D . decision\n",
      "A\n",
      "A\n",
      "correct\n"
     ]
    }
   ],
   "source": [
    "raw_text = nytimes\n",
    "doc = nlp(raw_text)\n",
    "sentences = [str(t) for t in doc.sents]\n",
    "\n",
    "words = random.sample(words, len(words))\n",
    "\n",
    "lc = 0\n",
    "for l in range (len(words)):\n",
    "    step_2 = sent_w_word (sentences, words[l])\n",
    "    if step_2 is not None:\n",
    "        if lc < 5:\n",
    "            correct_anwser = words[l]\n",
    "            s = nlp_my.get_synonyms_spacy_english(words[l], 3)\n",
    "            list_of_other_words = [words[l]] + s\n",
    "            to = ela_quiz(step_2, words[l], list_of_other_words)\n",
    "            correct = 0\n",
    "            while (correct == 0):\n",
    "                inpot = input()\n",
    "                if inpot == to[correct_anwser]:\n",
    "                    correct = 1\n",
    "                    print(\"correct\")\n",
    "                else:\n",
    "                    correct = 0\n",
    "                    print(\"inncorrect\")\n",
    "                \n",
    "        lc = lc + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-95425fb2c79c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'to' is not defined"
     ]
    }
   ],
   "source": [
    "print(to)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
